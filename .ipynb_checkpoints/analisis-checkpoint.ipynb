{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4674fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS EXPLORATORIO DE DATOS - NECROPSIAS GUATEMALA (INE)\n",
    "# Universidad del Valle de Guatemala - CC3074 Minería de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82881e",
   "metadata": {},
   "source": [
    "## 1. CONFIGURACIÓN INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41d91ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Librerías cargadas exitosamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyreadstat\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, normaltest, chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "os.makedirs('resultados', exist_ok=True)\n",
    "os.makedirs('graficos', exist_ok=True)\n",
    "\n",
    "print(\" Librerías cargadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe904e6",
   "metadata": {},
   "source": [
    "## 2. CARGA Y UNIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b803fa70",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Archivos encontrados: 11\n",
      "   - necropsias2011.sav\n",
      "   - necropsias2012.sav\n",
      "   - necropsias2016.sav\n",
      "   - necropsias2017.sav\n",
      "   - necropsias2018.sav\n",
      "   - necropsias2019.sav\n",
      "   - necropsias2020.sav\n",
      "   - necropsias2021.sav\n",
      "   - necropsias2022.sav\n",
      "   - necropsias2023.sav\n",
      "   - necropsias2024.sav\n"
     ]
    }
   ],
   "source": [
    "# Usar directorio actual\n",
    "ruta_datos = \".\"\n",
    "\n",
    "archivos = glob.glob(os.path.join(ruta_datos, \"necropsias*.sav\"))\n",
    "print(f\"\\n Archivos encontrados: {len(archivos)}\")\n",
    "for archivo in sorted(archivos):\n",
    "    print(f\"   - {os.path.basename(archivo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b804a4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "necropsias2011.sav: 13137 registros\n",
      "necropsias2012.sav: 12753 registros\n",
      "necropsias2016.sav: 12179 registros\n",
      "necropsias2017.sav: 11848 registros\n",
      "necropsias2018.sav: 11512 registros\n",
      "necropsias2019.sav: 11351 registros\n",
      "necropsias2020.sav: 8819 registros\n",
      "necropsias2021.sav: 10281 registros\n",
      "necropsias2022.sav: 10729 registros\n",
      "necropsias2023.sav: 11038 registros\n",
      "necropsias2024.sav: 2598 registros\n",
      "\n",
      " Uniendo todos los datasets...\n",
      " DATOS CARGADOS EXITOSAMENTE\n",
      "\n",
      " Total de registros: 116,245\n",
      " Total de variables: 31\n",
      " Años disponibles: [np.int64(2011), np.int64(2012), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021), np.int64(2022), np.int64(2023), np.int64(2024)]\n"
     ]
    }
   ],
   "source": [
    "def cargar_necropsia(archivo):\n",
    "    \"\"\"Carga un archivo .sav de necropsias y agrega columna de año\"\"\"\n",
    "    nombre_archivo = os.path.basename(archivo)\n",
    "    anio = re.search(r'(\\d{4})', nombre_archivo)\n",
    "    \n",
    "    if anio:\n",
    "        anio = int(anio.group(1))\n",
    "    else:\n",
    "        print(f\"No se pudo extraer el año de: {nombre_archivo}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df, meta = pyreadstat.read_sav(archivo)\n",
    "        df['anio'] = anio\n",
    "        print(f\"{nombre_archivo}: {len(df)} registros\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar {nombre_archivo}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "lista_dataframes = []\n",
    "for archivo in sorted(archivos):\n",
    "    df = cargar_necropsia(archivo)\n",
    "    if df is not None:\n",
    "        lista_dataframes.append(df)\n",
    "\n",
    "print(\"\\n Uniendo todos los datasets...\")\n",
    "necropsias = pd.concat(lista_dataframes, ignore_index=True, sort=False)\n",
    "\n",
    "print(f\" DATOS CARGADOS EXITOSAMENTE\")\n",
    "print(f\"\\n Total de registros: {len(necropsias):,}\")\n",
    "print(f\" Total de variables: {len(necropsias.columns)}\")\n",
    "print(f\" Años disponibles: {sorted(necropsias['anio'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83c8c1",
   "metadata": {},
   "source": [
    "## 3. LIMPIEZA Y CONSOLIDACIÓN DE DATOS\n",
    "\n",
    "Los archivos de diferentes años tienen nombres de variables ligeramente distintos.\n",
    "Consolidamos las variables duplicadas para tener un dataset uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f92429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. LIMPIEZA Y CONSOLIDACIÓN DE DATOS\n",
      "\n",
      " Consolidando variable EDAD...\n",
      "    edad: 114,692 valores válidos\n",
      "\n",
      " Consolidando variable SEXO...\n",
      "    sexo: 115,286 valores válidos\n",
      "\n",
      " Consolidando variable MES...\n",
      "    mes: 116,245 valores válidos\n",
      "\n",
      " Consolidando variable DÍA DE LA SEMANA...\n",
      "    dia_semana: 46,890 valores válidos\n",
      "\n",
      " Consolidando variable CAUSA DE MUERTE...\n",
      "    causa: 116,245 valores válidos\n",
      "\n",
      " Consolidando variable MUNICIPIO...\n",
      "    municipio: 78,176 valores válidos\n",
      "\n",
      " Dataset limpio creado con 8 variables consolidadas\n",
      " Registros totales: 116,245\n",
      "\n",
      " Valores faltantes después de consolidación:\n",
      "   anio           : 0 (0.0%)\n",
      "   mes            : 0 (0.0%)\n",
      "   dia_semana     : 69,355 (59.7%)\n",
      "   departamento   : 0 (0.0%)\n",
      "   municipio      : 38,069 (32.7%)\n",
      "   edad           : 1,553 (1.3%)\n",
      "   sexo           : 959 (0.8%)\n",
      "   causa          : 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"3. LIMPIEZA Y CONSOLIDACIÓN DE DATOS\")\n",
    "\n",
    "# 3.1 Consolidar variables de EDAD\n",
    "print(\"\\n Consolidando variable EDAD...\")\n",
    "necropsias['edad'] = necropsias['edad_per'].fillna(necropsias['edad_person'])\n",
    "# Limpiar valores inválidos (999 = desconocido según INE)\n",
    "necropsias.loc[necropsias['edad'] >= 999, 'edad'] = np.nan\n",
    "print(f\"    edad: {necropsias['edad'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.2 Consolidar variables de SEXO\n",
    "print(\"\\n Consolidando variable SEXO...\")\n",
    "necropsias['sexo'] = necropsias['sexo_per'].fillna(\n",
    "    necropsias['sexo_person'].fillna(necropsias['sexo_per_eva'])\n",
    ")\n",
    "# Codificar: 1=Hombre, 2=Mujer, 9=No especificado\n",
    "necropsias.loc[necropsias['sexo'] == 9, 'sexo'] = np.nan\n",
    "print(f\"    sexo: {necropsias['sexo'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.3 Consolidar MES de ocurrencia\n",
    "print(\"\\n Consolidando variable MES...\")\n",
    "necropsias['mes'] = necropsias['mes_ocu'].fillna(necropsias['mes_ing'])\n",
    "print(f\"    mes: {necropsias['mes'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.4 Consolidar DÍA DE LA SEMANA\n",
    "print(\"\\n Consolidando variable DÍA DE LA SEMANA...\")\n",
    "necropsias['dia_semana'] = necropsias['diasem_ocu'].fillna(\n",
    "    necropsias['día_sem_ocu'].fillna(necropsias['dia_sem_ocu'])\n",
    ")\n",
    "print(f\"    dia_semana: {necropsias['dia_semana'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.5 Consolidar CAUSA DE MUERTE\n",
    "print(\"\\n Consolidando variable CAUSA DE MUERTE...\")\n",
    "necropsias['causa'] = necropsias['causa_muerte'].fillna(necropsias['eva_mn'])\n",
    "print(f\"    causa: {necropsias['causa'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.6 Consolidar MUNICIPIO\n",
    "print(\"\\n Consolidando variable MUNICIPIO...\")\n",
    "necropsias['municipio'] = necropsias['mupio_ocu']\n",
    "print(f\"    municipio: {necropsias['municipio'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.7 Consolidar DEPARTAMENTO\n",
    "necropsias['departamento'] = necropsias['depto_ocu']\n",
    "\n",
    "# Crear dataset limpio con variables consolidadas\n",
    "vars_limpias = ['anio', 'mes', 'dia_semana', 'departamento', 'municipio', \n",
    "                'edad', 'sexo', 'causa']\n",
    "df_limpio = necropsias[vars_limpias].copy()\n",
    "\n",
    "print(f\"\\n Dataset limpio creado con {len(vars_limpias)} variables consolidadas\")\n",
    "print(f\" Registros totales: {len(df_limpio):,}\")\n",
    "\n",
    "# Resumen de valores faltantes después de limpieza\n",
    "print(\"\\n Valores faltantes después de consolidación:\")\n",
    "for col in vars_limpias:\n",
    "    faltantes = df_limpio[col].isna().sum()\n",
    "    pct = faltantes / len(df_limpio) * 100\n",
    "    print(f\"   {col:15s}: {faltantes:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d774713",
   "metadata": {},
   "source": [
    "## 4. DESCRIPCIÓN DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d8edc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. DESCRIPCIÓN DEL DATASET\n",
      "\n",
      " Dimensiones del dataset limpio:\n",
      "   - Observaciones (filas): 116,245\n",
      "   - Variables (columnas): 8\n",
      "\n",
      " Variables y tipos:\n",
      "   anio            | int64      | 116,245 valores\n",
      "   mes             | float64    | 116,245 valores\n",
      "   dia_semana      | float64    | 46,890 valores\n",
      "   departamento    | float64    | 116,245 valores\n",
      "   municipio       | float64    | 78,176 valores\n",
      "   edad            | float64    | 114,692 valores\n",
      "   sexo            | float64    | 115,286 valores\n",
      "   causa           | float64    | 116,245 valores\n"
     ]
    }
   ],
   "source": [
    "print(\"4. DESCRIPCIÓN DEL DATASET\")\n",
    "\n",
    "print(f\"\\n Dimensiones del dataset limpio:\")\n",
    "print(f\"   - Observaciones (filas): {df_limpio.shape[0]:,}\")\n",
    "print(f\"   - Variables (columnas): {df_limpio.shape[1]}\")\n",
    "\n",
    "print(f\"\\n Variables y tipos:\")\n",
    "for col in df_limpio.columns:\n",
    "    tipo = str(df_limpio[col].dtype)\n",
    "    no_nulos = df_limpio[col].notna().sum()\n",
    "    print(f\"   {col:15s} | {tipo:10s} | {no_nulos:,} valores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a58312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Estadísticas descriptivas:\n",
      "                anio            mes    dia_semana   departamento  \\\n",
      "count  116245.000000  116245.000000  46890.000000  116245.000000   \n",
      "mean     2017.731971       6.444380      4.118810       7.750914   \n",
      "std         3.973489       3.508789      2.088353       7.211122   \n",
      "min      2011.000000       1.000000      1.000000       1.000000   \n",
      "25%      2016.000000       3.000000      2.000000       1.000000   \n",
      "50%      2018.000000       6.000000      4.000000       5.000000   \n",
      "75%      2021.000000      10.000000      6.000000      14.000000   \n",
      "max      2024.000000      12.000000      7.000000      99.000000   \n",
      "\n",
      "          municipio           edad           sexo          causa  \n",
      "count  78176.000000  114692.000000  115286.000000  116245.000000  \n",
      "mean     795.524048      35.006766       1.174488      19.291247  \n",
      "std      719.766829      18.124620       0.379530      13.435863  \n",
      "min      101.000000       0.000000       1.000000       1.000000  \n",
      "25%      108.000000      22.000000       1.000000       4.000000  \n",
      "50%      506.000000      31.000000       1.000000      20.000000  \n",
      "75%     1501.000000      45.000000       1.000000      37.000000  \n",
      "max     9999.000000     100.000000       2.000000      43.000000  \n"
     ]
    }
   ],
   "source": [
    "# Estadísticas descriptivas\n",
    "print(\"\\n Estadísticas descriptivas:\")\n",
    "print(df_limpio.describe())\n",
    "\n",
    "# Guardar\n",
    "df_limpio.describe().to_csv('resultados/estadisticas_descriptivas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225653b-3c95-4997-b808-6e52095fc0b7",
   "metadata": {},
   "source": [
    "## 5. ANÁLISIS DE VARIABLES NUMÉRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c160b-9d9a-4b5d-bd80-3a079df62d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"5. ANÁLISIS DE VARIABLES NUMÉRICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 5.1 EDAD - Análisis detallado\n",
    "print(\"\\n 5.1 Análisis de EDAD\")\n",
    "edad_valida = df_limpio['edad'].dropna()\n",
    "print(f\"   N válido: {len(edad_valida):,}\")\n",
    "print(f\"   Media: {edad_valida.mean():.2f} años\")\n",
    "print(f\"   Mediana: {edad_valida.median():.2f} años\")\n",
    "print(f\"   Desv. Est.: {edad_valida.std():.2f}\")\n",
    "print(f\"   Mínimo: {edad_valida.min():.0f}\")\n",
    "print(f\"   Máximo: {edad_valida.max():.0f}\")\n",
    "print(f\"   Asimetría: {edad_valida.skew():.3f}\")\n",
    "print(f\"   Curtosis: {edad_valida.kurtosis():.3f}\")\n",
    "\n",
    "# Prueba de normalidad D'Agostino-Pearson (para muestras grandes)\n",
    "if len(edad_valida) > 8:\n",
    "    stat, p_value = normaltest(edad_valida.sample(min(5000, len(edad_valida))))\n",
    "    print(f\"\\n   Test D'Agostino-Pearson:\")\n",
    "    print(f\"   Estadístico: {stat:.4f}, p-value: {p_value:.6f}\")\n",
    "    print(f\"   {' NO sigue distribución normal' if p_value < 0.05 else ' Sigue distribución normal'}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
