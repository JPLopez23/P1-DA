{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4674fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS EXPLORATORIO DE DATOS - NECROPSIAS GUATEMALA (INE)\n",
    "# Universidad del Valle de Guatemala - CC3074 Minería de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82881e",
   "metadata": {},
   "source": [
    "## 1. CONFIGURACIÓN INICIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyreadstat\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, normaltest, chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "import glob\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "os.makedirs('resultados', exist_ok=True)\n",
    "os.makedirs('graficos', exist_ok=True)\n",
    "\n",
    "print(\" Librerías cargadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe904e6",
   "metadata": {},
   "source": [
    "## 2. CARGA Y UNIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803fa70",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Usar directorio actual\n",
    "ruta_datos = \".\"\n",
    "\n",
    "archivos = glob.glob(os.path.join(ruta_datos, \"necropsias*.sav\"))\n",
    "print(f\"\\n Archivos encontrados: {len(archivos)}\")\n",
    "for archivo in sorted(archivos):\n",
    "    print(f\"   - {os.path.basename(archivo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b804a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_necropsia(archivo):\n",
    "    \"\"\"Carga un archivo .sav de necropsias y agrega columna de año\"\"\"\n",
    "    nombre_archivo = os.path.basename(archivo)\n",
    "    anio = re.search(r'(\\d{4})', nombre_archivo)\n",
    "    \n",
    "    if anio:\n",
    "        anio = int(anio.group(1))\n",
    "    else:\n",
    "        print(f\"No se pudo extraer el año de: {nombre_archivo}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df, meta = pyreadstat.read_sav(archivo)\n",
    "        df['anio'] = anio\n",
    "        print(f\"{nombre_archivo}: {len(df)} registros\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar {nombre_archivo}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "lista_dataframes = []\n",
    "for archivo in sorted(archivos):\n",
    "    df = cargar_necropsia(archivo)\n",
    "    if df is not None:\n",
    "        lista_dataframes.append(df)\n",
    "\n",
    "print(\"\\n Uniendo todos los datasets...\")\n",
    "necropsias = pd.concat(lista_dataframes, ignore_index=True, sort=False)\n",
    "\n",
    "print(f\" DATOS CARGADOS EXITOSAMENTE\")\n",
    "print(f\"\\n Total de registros: {len(necropsias):,}\")\n",
    "print(f\" Total de variables: {len(necropsias.columns)}\")\n",
    "print(f\" Años disponibles: {sorted(necropsias['anio'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83c8c1",
   "metadata": {},
   "source": [
    "## 3. LIMPIEZA Y CONSOLIDACIÓN DE DATOS\n",
    "\n",
    "Los archivos de diferentes años tienen nombres de variables ligeramente distintos.\n",
    "Consolidamos las variables duplicadas para tener un dataset uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"3. LIMPIEZA Y CONSOLIDACIÓN DE DATOS\")\n",
    "\n",
    "# 3.1 Consolidar variables de EDAD\n",
    "print(\"\\n Consolidando variable EDAD...\")\n",
    "necropsias['edad'] = necropsias['edad_per'].fillna(necropsias['edad_person'])\n",
    "# Limpiar valores inválidos (999 = desconocido según INE)\n",
    "necropsias.loc[necropsias['edad'] >= 999, 'edad'] = np.nan\n",
    "print(f\"    edad: {necropsias['edad'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.2 Consolidar variables de SEXO\n",
    "print(\"\\n Consolidando variable SEXO...\")\n",
    "necropsias['sexo'] = necropsias['sexo_per'].fillna(\n",
    "    necropsias['sexo_person'].fillna(necropsias['sexo_per_eva'])\n",
    ")\n",
    "# Codificar: 1=Hombre, 2=Mujer, 9=No especificado\n",
    "necropsias.loc[necropsias['sexo'] == 9, 'sexo'] = np.nan\n",
    "print(f\"    sexo: {necropsias['sexo'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.3 Consolidar MES de ocurrencia\n",
    "print(\"\\n Consolidando variable MES...\")\n",
    "necropsias['mes'] = necropsias['mes_ocu'].fillna(necropsias['mes_ing'])\n",
    "print(f\"    mes: {necropsias['mes'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.4 Consolidar DÍA DE LA SEMANA\n",
    "print(\"\\n Consolidando variable DÍA DE LA SEMANA...\")\n",
    "necropsias['dia_semana'] = necropsias['diasem_ocu'].fillna(\n",
    "    necropsias['día_sem_ocu'].fillna(necropsias['dia_sem_ocu'])\n",
    ")\n",
    "print(f\"    dia_semana: {necropsias['dia_semana'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.5 Consolidar CAUSA DE MUERTE\n",
    "print(\"\\n Consolidando variable CAUSA DE MUERTE...\")\n",
    "necropsias['causa'] = necropsias['causa_muerte'].fillna(necropsias['eva_mn'])\n",
    "print(f\"    causa: {necropsias['causa'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.6 Consolidar MUNICIPIO\n",
    "print(\"\\n Consolidando variable MUNICIPIO...\")\n",
    "necropsias['municipio'] = necropsias['mupio_ocu']\n",
    "print(f\"    municipio: {necropsias['municipio'].notna().sum():,} valores válidos\")\n",
    "\n",
    "# 3.7 Consolidar DEPARTAMENTO\n",
    "necropsias['departamento'] = necropsias['depto_ocu']\n",
    "\n",
    "# Crear dataset limpio con variables consolidadas\n",
    "vars_limpias = ['anio', 'mes', 'dia_semana', 'departamento', 'municipio', \n",
    "                'edad', 'sexo', 'causa']\n",
    "df_limpio = necropsias[vars_limpias].copy()\n",
    "\n",
    "print(f\"\\n Dataset limpio creado con {len(vars_limpias)} variables consolidadas\")\n",
    "print(f\" Registros totales: {len(df_limpio):,}\")\n",
    "\n",
    "# Resumen de valores faltantes después de limpieza\n",
    "print(\"\\n Valores faltantes después de consolidación:\")\n",
    "for col in vars_limpias:\n",
    "    faltantes = df_limpio[col].isna().sum()\n",
    "    pct = faltantes / len(df_limpio) * 100\n",
    "    print(f\"   {col:15s}: {faltantes:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d774713",
   "metadata": {},
   "source": [
    "## 4. DESCRIPCIÓN DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8edc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"4. DESCRIPCIÓN DEL DATASET\")\n",
    "\n",
    "print(f\"\\n Dimensiones del dataset limpio:\")\n",
    "print(f\"   - Observaciones (filas): {df_limpio.shape[0]:,}\")\n",
    "print(f\"   - Variables (columnas): {df_limpio.shape[1]}\")\n",
    "\n",
    "print(f\"\\n Variables y tipos:\")\n",
    "for col in df_limpio.columns:\n",
    "    tipo = str(df_limpio[col].dtype)\n",
    "    no_nulos = df_limpio[col].notna().sum()\n",
    "    print(f\"   {col:15s} | {tipo:10s} | {no_nulos:,} valores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a58312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "print(\"\\n Estadísticas descriptivas:\")\n",
    "print(df_limpio.describe())\n",
    "\n",
    "# Guardar\n",
    "df_limpio.describe().to_csv('resultados/estadisticas_descriptivas.csv')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
